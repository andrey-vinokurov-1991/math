{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-dimensional Gradient Descent**\n",
    "\n",
    "To find the minimum of differentiable function $f : [a, b] \\rightarrow \\mathbb{R}$ we can use the following **One-dimensional $Gradient$ $Descent$ Algorithm **\n",
    "\n",
    "1. Choose a point  $r_1 \\in [a, b]$\n",
    "2. Define $i$ as a step number of Gradient Descent. For now it is $i = 1$\n",
    "3. Calculate $f'(r_i)$.\n",
    "4. If $f'(r_i)=0$: the algorithm stops.  \n",
    "   If $f'(r_i)>0$: we should move to left, so we choose $\\delta > 0$ and assign $r_{i+1}=r_i-\\delta$.  \n",
    "   If $f'(r_i)<0$: we should move to right, so we choose $\\delta > 0$ and assign $r_{i+1}=r_i+\\delta$.  \n",
    "5. Replace $i$ to $i+1$ and repeat the steps 3, 4 and 5.\n",
    "\n",
    "If in Gradient Descent Algorithm we take a step $-\\lambda f'(r_i)$ for some positive value $\\lambda > 0$, then this $\\lambda$ is called $learning\\ rate$. In this case in the point 4 of the algorithm $r_{i+1}=r_i-\\lambda f'(r_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\mathbb{R}$: distances and vectors**  \n",
    "$\\mathbb{R}$ - is a set of ordered arrays $(x_1, x_2,...,x_n)$ , such as $\\forall \\ i : x_i \\in \\mathbb{R}$. Each of this array is called $point \\ in \\ \\mathbb{R}$.\n",
    "We call $f$ as $a \\ function \\ of \\ many \\ variables$, if $f$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
